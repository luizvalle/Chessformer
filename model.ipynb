{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a6f4f0-cf63-4588-a888-e57cc37f5355",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b04ffbdf-d133-4191-ad92-4d9e644a8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399025ed-93fa-48b2-b8e1-70822332edca",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c2315f77-2c14-4600-9535-7f7f9bebd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_description = {\n",
    "    \"moves\": tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    \"white_elo\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"black_elo\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"result\": tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "}\n",
    "\n",
    "def parse_example(example_proto):\n",
    "    example = tf.io.parse_example(example_proto, feature_description)\n",
    "    return example\n",
    "    \n",
    "TRAINING_DATA_DIR = \"data/training_data\"\n",
    "SHUFFLE_BUFFER_SIZE = 1024\n",
    "\n",
    "data_files = [f\"{TRAINING_DATA_DIR}/{file}\" for file in os.listdir(TRAINING_DATA_DIR)]\n",
    "dataset = tf.data.TFRecordDataset(filenames=data_files,\n",
    "                                  compression_type=\"ZLIB\",\n",
    "                                  num_parallel_reads=4)\n",
    "dataset = dataset.map(parse_example).shuffle(SHUFFLE_BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "76fddd66-02b6-4dd4-a7b8-c37533ccd878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_size(dataset):\n",
    "    length = 0\n",
    "    for item in dataset:\n",
    "        length += 1\n",
    "    return length\n",
    "\n",
    "TRAIN_SPLIT = 0.8\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "dataset_size = get_size(dataset)\n",
    "train_size = int(dataset_size * TRAIN_SPLIT)\n",
    "train_dataset = dataset.take(train_size).cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = dataset.skip(train_size).cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d1d89-4933-4ad9-b9c8-7649440adf94",
   "metadata": {},
   "source": [
    "## InputEmbedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "597bdfeb-0135-4c41-b2e6-a7a4bfb4af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocabulary, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.vectorize_layer = tf.keras.layers.TextVectorization(\n",
    "            output_mode=\"int\",\n",
    "            vocabulary=vocabulary,\n",
    "            standardize=None,\n",
    "            split=\"whitespace\"\n",
    "        )\n",
    "        vocab_size = vectorize_layer.vocabulary_size()\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.vectorize_layer(x)\n",
    "        x = self.embedding_layer(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e9663801-a7de-4033-a169-5bdf612f19eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'p e2 e4 - p d7 d5 - p e4 d5 - n g8 f6 - n b1 c3 - p e7 e6 - b f1 c4 - b f8 b4 - q d1 f3 - n b8 d7 - p b2 b3 - n d7 c5 - b c1 b2 - b b4 c3 - b b2 c3 - k e8 g8 - p d5 e6 - b c8 e6 - b c4 e6 - r f8 e8 - n g1 e2 - r e8 e6 - k e1 g1 - q d8 e7 - n e2 f4 - r e6 c6 - b c3 f6 - q e7 f6 - r f1 e1 - n c5 d7 - r e1 e2 - q f6 a1 - r e2 e1 - q a1 e1 -'], shape=(1,), dtype=string)\n",
      "tf.Tensor(\n",
      "[[ 2 20 36 72  2 59 43 72  2 36 43 72  3 70 53 72  3  9 26 72  2 60 52 72\n",
      "   4 13 34 72  4 69 33 72  6 11 29 72  3 65 59 72  2 17 25 72  3 59 42 72\n",
      "   4 10 17 72  4 33 26 72  4 17 26 72  7 68 70 72  2 43 52 72  4 66 52 72\n",
      "   4 34 52 72  5 69 68 72  3 14 20 72  5 68 52 72  7 12 14 72  6 67 60 72\n",
      "   3 20 37 72  5 52 50 72  4 26 53 72  6 60 53 72  5 13 12 72  3 42 59 72\n",
      "   5 12 20 72  6 53  8 72  5 20 12 72  6  8 12 72]], shape=(1, 136), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[[-0.01530797 -0.0104291 ]\n",
      "  [-0.01870643  0.01906184]\n",
      "  [ 0.05186082  0.05012989]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.01530797 -0.0104291 ]\n",
      "  [-0.05132679  0.06622922]\n",
      "  [-0.06228676 -0.04217809]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.01530797 -0.0104291 ]\n",
      "  [ 0.05186082  0.05012989]\n",
      "  [-0.06228676 -0.04217809]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.01757917 -0.03981149]\n",
      "  [-0.00456418 -0.06009094]\n",
      "  [ 0.02936415  0.02675554]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.01757917 -0.03981149]\n",
      "  [ 0.05146892  0.01493093]\n",
      "  [-0.06024535  0.00968553]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.01530797 -0.0104291 ]\n",
      "  [-0.04266234 -0.02627096]\n",
      "  [-0.00662921  0.03919728]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.05697664  0.04182174]\n",
      "  [-0.04559712  0.03527001]\n",
      "  [-0.05127344  0.0657823 ]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.05697664  0.04182174]\n",
      "  [ 0.04314057 -0.04953931]\n",
      "  [-0.01965844  0.02366841]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.04968306  0.03241696]\n",
      "  [ 0.02230467 -0.00083383]\n",
      "  [-0.02720481 -0.01320567]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.01757917 -0.03981149]\n",
      "  [-0.03995081  0.05678443]\n",
      "  [-0.05132679  0.06622922]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.01530797 -0.0104291 ]\n",
      "  [ 0.06611411  0.05734126]\n",
      "  [ 0.0139453  -0.07035661]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.01757917 -0.03981149]\n",
      "  [-0.05132679  0.06622922]\n",
      "  [-0.05340472 -0.05682391]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.05697664  0.04182174]\n",
      "  [-0.00080832  0.05317315]\n",
      "  [ 0.06611411  0.05734126]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.05697664  0.04182174]\n",
      "  [-0.01965844  0.02366841]\n",
      "  [-0.06024535  0.00968553]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.05697664  0.04182174]\n",
      "  [ 0.06611411  0.05734126]\n",
      "  [-0.06024535  0.00968553]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.01247216 -0.06999072]\n",
      "  [ 0.04847344 -0.00509321]\n",
      "  [-0.00456418 -0.06009094]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.01530797 -0.0104291 ]\n",
      "  [-0.06228676 -0.04217809]\n",
      "  [-0.00662921  0.03919728]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.05697664  0.04182174]\n",
      "  [ 0.03447001  0.00815106]\n",
      "  [-0.00662921  0.03919728]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.05697664  0.04182174]\n",
      "  [-0.05127344  0.0657823 ]\n",
      "  [-0.00662921  0.03919728]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.02844793  0.02855399]\n",
      "  [ 0.04314057 -0.04953931]\n",
      "  [ 0.04847344 -0.00509321]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.01757917 -0.03981149]\n",
      "  [ 0.05964839  0.00667329]\n",
      "  [-0.01870643  0.01906184]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.02844793  0.02855399]\n",
      "  [ 0.04847344 -0.00509321]\n",
      "  [-0.00662921  0.03919728]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.01247216 -0.06999072]\n",
      "  [-0.00805851 -0.06707658]\n",
      "  [ 0.05964839  0.00667329]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.04968306  0.03241696]\n",
      "  [ 0.03139062  0.05396759]\n",
      "  [-0.04266234 -0.02627096]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.01757917 -0.03981149]\n",
      "  [-0.01870643  0.01906184]\n",
      "  [ 0.05625456 -0.01763134]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.02844793  0.02855399]\n",
      "  [-0.00662921  0.03919728]\n",
      "  [ 0.06160652 -0.06521824]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.05697664  0.04182174]\n",
      "  [-0.06024535  0.00968553]\n",
      "  [ 0.02936415  0.02675554]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.04968306  0.03241696]\n",
      "  [-0.04266234 -0.02627096]\n",
      "  [ 0.02936415  0.02675554]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.02844793  0.02855399]\n",
      "  [-0.04559712  0.03527001]\n",
      "  [-0.00805851 -0.06707658]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.01757917 -0.03981149]\n",
      "  [-0.05340472 -0.05682391]\n",
      "  [-0.05132679  0.06622922]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.02844793  0.02855399]\n",
      "  [-0.00805851 -0.06707658]\n",
      "  [-0.01870643  0.01906184]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.04968306  0.03241696]\n",
      "  [ 0.02936415  0.02675554]\n",
      "  [ 0.014449    0.02099678]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [ 0.02844793  0.02855399]\n",
      "  [-0.01870643  0.01906184]\n",
      "  [-0.00805851 -0.06707658]\n",
      "  [ 0.06932258  0.00086015]\n",
      "  [-0.04968306  0.03241696]\n",
      "  [ 0.014449    0.02099678]\n",
      "  [-0.00805851 -0.06707658]\n",
      "  [ 0.06932258  0.00086015]]], shape=(1, 136, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 17:16:55.645227: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "pieces = [\"p\", \"n\", \"b\", \"r\", \"q\", \"k\"]\n",
    "rank_names = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]\n",
    "file_names = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "squares = [f + r for r in rank_names for f in file_names]\n",
    "promotions = [\"-\", \"=n\", \"=b\", \"=r\", \"=q\"]\n",
    "vocabulary = pieces + squares + promotions\n",
    "\n",
    "embedding = InputEmbedding(vocabulary, 2)\n",
    "for example in train_dataset.batch(1).take(1):\n",
    "    print(example[\"moves\"])\n",
    "    print(vectorize_layer(example[\"moves\"]))\n",
    "    print(embedding(example[\"moves\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
