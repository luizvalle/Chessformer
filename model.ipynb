{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a6f4f0-cf63-4588-a888-e57cc37f5355",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b04ffbdf-d133-4191-ad92-4d9e644a8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399025ed-93fa-48b2-b8e1-70822332edca",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2315f77-2c14-4600-9535-7f7f9bebd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_DIR = \"data/training_data\"\n",
    "\n",
    "data_files = [f\"{TRAINING_DATA_DIR}/{file}\" for file in os.listdir(TRAINING_DATA_DIR)]\n",
    "dataset = tf.data.TFRecordDataset(filenames=data_files,\n",
    "                                  compression_type=\"GZIP\",\n",
    "                                  num_parallel_reads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9d82c60-c58d-4231-8b80-086b166f1d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 -> [1. 0. 0.]\n",
      "1-0 -> [0. 1. 0.]\n",
      "1/2-1/2 -> [0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "possible_results = [\"0-1\", \"1-0\", \"1/2-1/2\"]\n",
    "result_to_onehot = tf.keras.layers.StringLookup(\n",
    "    vocabulary=possible_results,\n",
    "    # Ideally, this would be 0 but it returns a numpy error when 0.\n",
    "    # Instead, we will just remove the first dimension after applying\n",
    "    # this\n",
    "    num_oov_indices=1,\n",
    "    output_mode=\"one_hot\")\n",
    "\n",
    "for result in possible_results:\n",
    "    print(f\"{result} -> {result_to_onehot(result)[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "94b6304c-0e4c-460c-8323-6cf4b120e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example conversion\n",
      "Original: p e2 e4 - p a7 a5 - b f1 c4 - p c7 c5 - q d1 f3 - p e7 e5 - q f3 f7 -\n",
      "Vectorized: [ 2 20 36 72  2 56 40 72  4 13 34 72  2 58 42 72  6 11 29 72  2 60 44 72\n",
      "  6 29 61 72  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "p -> 2\n",
      "n -> 3\n",
      "b -> 4\n",
      "r -> 5\n",
      "q -> 6\n",
      "k -> 7\n",
      "a1 -> 8\n",
      "b1 -> 9\n",
      "c1 -> 10\n",
      "d1 -> 11\n",
      "e1 -> 12\n",
      "f1 -> 13\n",
      "g1 -> 14\n",
      "h1 -> 15\n",
      "a2 -> 16\n",
      "b2 -> 17\n",
      "c2 -> 18\n",
      "d2 -> 19\n",
      "e2 -> 20\n",
      "f2 -> 21\n",
      "g2 -> 22\n",
      "h2 -> 23\n",
      "a3 -> 24\n",
      "b3 -> 25\n",
      "c3 -> 26\n",
      "d3 -> 27\n",
      "e3 -> 28\n",
      "f3 -> 29\n",
      "g3 -> 30\n",
      "h3 -> 31\n",
      "a4 -> 32\n",
      "b4 -> 33\n",
      "c4 -> 34\n",
      "d4 -> 35\n",
      "e4 -> 36\n",
      "f4 -> 37\n",
      "g4 -> 38\n",
      "h4 -> 39\n",
      "a5 -> 40\n",
      "b5 -> 41\n",
      "c5 -> 42\n",
      "d5 -> 43\n",
      "e5 -> 44\n",
      "f5 -> 45\n",
      "g5 -> 46\n",
      "h5 -> 47\n",
      "a6 -> 48\n",
      "b6 -> 49\n",
      "c6 -> 50\n",
      "d6 -> 51\n",
      "e6 -> 52\n",
      "f6 -> 53\n",
      "g6 -> 54\n",
      "h6 -> 55\n",
      "a7 -> 56\n",
      "b7 -> 57\n",
      "c7 -> 58\n",
      "d7 -> 59\n",
      "e7 -> 60\n",
      "f7 -> 61\n",
      "g7 -> 62\n",
      "h7 -> 63\n",
      "a8 -> 64\n",
      "b8 -> 65\n",
      "c8 -> 66\n",
      "d8 -> 67\n",
      "e8 -> 68\n",
      "f8 -> 69\n",
      "g8 -> 70\n",
      "h8 -> 71\n",
      "- -> 72\n",
      "=n -> 73\n",
      "=b -> 74\n",
      "=r -> 75\n",
      "=q -> 76\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1024\n",
    "\n",
    "pieces = [\"p\", \"n\", \"b\", \"r\", \"q\", \"k\"]\n",
    "rank_names = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]\n",
    "file_names = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "squares = [f + r for r in rank_names for f in file_names]\n",
    "promotions = [\"-\", \"=n\", \"=b\", \"=r\", \"=q\"]\n",
    "possible_tokens = pieces + squares + promotions\n",
    "\n",
    "moves_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    output_mode=\"int\",\n",
    "    vocabulary=possible_tokens,\n",
    "    standardize=None,\n",
    "    split=\"whitespace\",\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "print(\"Example conversion\")\n",
    "sample_game = \"p e2 e4 - p a7 a5 - b f1 c4 - p c7 c5 - q d1 f3 - p e7 e5 - q f3 f7 -\"\n",
    "print(\"Original:\", sample_game)\n",
    "print(\"Vectorized:\", moves_vectorizer(sample_game).numpy()[:40])\n",
    "print()\n",
    "\n",
    "for token in possible_tokens:\n",
    "    print(f\"{token} -> {moves_vectorizer(token)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad4d06f5-b3c7-4a16-8946-db0b2e82a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "feature_description = {\n",
    "    \"moves\": tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    \"white_elo\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"black_elo\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"result\": tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "}\n",
    "\n",
    "def prepare_example(example_proto):\n",
    "    example = tf.io.parse_example(example_proto, feature_description)\n",
    "    # [:,1:] is used to remove out-of-vocabulary index\n",
    "    result_embedding = result_to_onehot(example[\"result\"])[:,1:]\n",
    "    tokenized_moves = moves_vectorizer(example[\"moves\"])\n",
    "    white_elo = tf.reshape(example[\"white_elo\"], shape=(-1,1))\n",
    "    black_elo = tf.reshape(example[\"black_elo\"], shape=(-1,1))\n",
    "    elos = tf.concat(values=[white_elo, black_elo], axis=1)\n",
    "    return tokenized_moves, elos, result_embedding\n",
    "\n",
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_example, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "ds = make_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d1d89-4933-4ad9-b9c8-7649440adf94",
   "metadata": {},
   "source": [
    "## InputEmbedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "597bdfeb-0135-4c41-b2e6-a7a4bfb4af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c18d01e7-bbbd-4408-bcbd-2ea031ba3ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1024, 5)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = moves_vectorizer.vocabulary_size()\n",
    "test_input_embedding = InputEmbedding(vocab_size=vocab_size, embedding_dim=5)\n",
    "for moves, elos, result in ds.take(1):\n",
    "    print(test_input_embedding(moves).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2525a-ddd9-442f-a895-bb3564eab8c8",
   "metadata": {},
   "source": [
    "## PositionalEmbedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acbe47b6-db96-4185-aac2-68ed8c150897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    half_depth = depth / 2\n",
    "    \n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(half_depth)[np.newaxis, :] / half_depth\n",
    "    \n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "    \n",
    "    pos_encoding = np.concatenate(\n",
    "        [np.sin(angle_rads), np.cos(angle_rads)],\n",
    "        axis=-1)\n",
    "    \n",
    "    return tf.cast(pos_encoding[:,:depth], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6e1ae8f3-9960-408a-a30a-6adab697cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.positional_embedding = positional_encoding(\n",
    "            length=2048, depth=embedding_dim)\n",
    "        \n",
    "    def call(self, x):\n",
    "        sequence_length = tf.shape(x)[1]\n",
    "        x += self.positional_embedding[tf.newaxis, :sequence_length, :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1bd7818-3856-4d50-a74c-c01f1fed1691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([65, 10, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 10\n",
    "dim = 5\n",
    "positional_embedding_test = PositionalEmbedding(dim)\n",
    "x = np.zeros((65, length, dim))\n",
    "positional_embedding_test(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92004ac-f447-45e3-bb39-1f1f4bdb04e8",
   "metadata": {},
   "source": [
    "## MultiHeadAttention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4098f3b7-3fb7-4adb-9daf-af99698f28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.dropout_layer = tf.keras.layers.Dropout(rate=dropout_rate)\n",
    " \n",
    "    def call(self, queries, keys, values, training):\n",
    "        d_k = tf.cast(values.shape[-1], tf.float32)\n",
    "        \n",
    "        scores = tf.linalg.matmul(queries, keys, transpose_b=True) / tf.math.sqrt(d_k)\n",
    " \n",
    "        weights = tf.nn.softmax(scores)\n",
    "\n",
    "        weights = self.dropout_layer(weights, training)\n",
    "\n",
    "        return tf.linalg.matmul(weights, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "55b244bf-6cd0-4754-909d-fa088d662ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, d_k, d_v, d_out, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_layer = DotProductAttention(dropout_rate)\n",
    "        # The dimension is d_k * num_heads so we can\n",
    "        # perform all computations in parallel\n",
    "        self.W_q = tf.keras.layers.Dense(d_k * num_heads)\n",
    "        self.W_k = tf.keras.layers.Dense(d_k * num_heads)\n",
    "        self.W_v = tf.keras.layers.Dense(d_v * num_heads)\n",
    "        self.W_o = tf.keras.layers.Dense(d_out)\n",
    "\n",
    "    def reshape_qkv(self, x, reverse=False):\n",
    "        if not reverse:\n",
    "            # x.shape == (num_batches, sequence_length, d * num_heads)\n",
    "            # where d in {d_k, d_v}\n",
    "            num_batches, sequence_length = tf.shape(x)[0], tf.shape(x)[1]\n",
    "            x = tf.reshape(x, shape=(num_batches, sequence_length, self.num_heads, -1))\n",
    "            x = tf.transpose(x, perm=(0, 2, 1, 3))\n",
    "            # Now x.shape == (num_batches, num_heads, sequence_length, d)\n",
    "        else:\n",
    "            num_batches, num_heads, sequence_length, d = tf.shape(x)[0], tf.shape(x)[1], tf.shape(x)[2], tf.shape(x)[3]\n",
    "            x = tf.transpose(x, perm=(0, 2, 1, 3))\n",
    "            x = tf.reshape(x, shape=(num_batches, sequence_length, d * num_heads))\n",
    "        return x\n",
    "        \n",
    "    def call(self, queries, keys, values, training=None):\n",
    "        q_reshaped = self.reshape_qkv(self.W_q(queries))\n",
    "        k_reshaped = self.reshape_qkv(self.W_k(keys))\n",
    "        v_reshaped = self.reshape_qkv(self.W_v(values))\n",
    "\n",
    "        output_reshaped = self.attention_layer(q_reshaped, k_reshaped, v_reshaped, training)\n",
    "        output = self.reshape_qkv(output_reshaped, reverse=True)\n",
    "\n",
    "        return self.W_o(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d791274-5aed-4efb-aa26-439a8b2fd7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 5, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "num_heads = 8  # Number of self-attention heads\n",
    "d_k = 64  # Dimensionality of the linearly projected queries and keys\n",
    "d_v = 128  # Dimensionality of the linearly projected values\n",
    "d_out = 512  # Dimensionality of the model sub-layers' outputs\n",
    "batch_size = 64  # Batch size from the training process\n",
    "dropout_rate = 0.1 # The dropout propability for the attention weights\n",
    " \n",
    "queries = np.random.random((batch_size, input_seq_length, d_k))\n",
    "keys = np.random.random((batch_size, input_seq_length, d_k))\n",
    "values = np.random.random((batch_size, input_seq_length, d_v))\n",
    "\n",
    "multihead_attention_test = MultiHeadAttention(num_heads, d_k, d_v, d_out, dropout_rate)\n",
    "\n",
    "multihead_attention_test(queries, keys, values).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae5bf79-e601-40a6-ae20-0df52f71e30d",
   "metadata": {},
   "source": [
    "## GlobalSelfAttention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68391473-3325-45aa-820f-b090e5a884e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalSelfAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, d_k, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.multihead_attention_layer = MultiHeadAttention(num_heads, d_k, d_k, d_k, dropout_rate)\n",
    "        self.add_layer = tf.keras.layers.Add()\n",
    "        self.normalization_layer = tf.keras.layers.LayerNormalization()\n",
    "\n",
    "    def call(self, x):\n",
    "        attention_output = self.multihead_attention_layer(\n",
    "            queries=x, keys=x, values=x)\n",
    "        x = self.add_layer([x, attention_output])\n",
    "        x = self.normalization_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9cc61ce-8907-4433-baeb-1c1604b0182d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 5, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "num_heads = 8  # Number of self-attention heads\n",
    "d_k = 512  # Dimensionality of the linearly projected queries and keys\n",
    "batch_size = 64  # Batch size from the training process\n",
    "dropout_rate = 0.1 # The dropout propability for the attention weights\n",
    " \n",
    "x = np.random.random((batch_size, input_seq_length, d_k))\n",
    "\n",
    "self_attention_test = GlobalSelfAttention(num_heads, d_k, dropout_rate)\n",
    "self_attention_test(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff252121-4df3-43b2-9128-2d4be11d16ce",
   "metadata": {},
   "source": [
    "## FeedForward Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a7c45439-2585-49ff-baea-38345dd79b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_k, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.seq = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),\n",
    "            tf.keras.layers.Dense(d_k),\n",
    "            tf.keras.layers.Dropout(dropout_rate)\n",
    "        ])\n",
    "        self.add_layer = tf.keras.layers.Add()\n",
    "        self.normalization_layer = tf.keras.layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.add_layer([x, self.seq(x)])\n",
    "        x = self.normalization_layer(x) \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2bb4d4c-e18a-4003-b179-493f12baa624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 5, 512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "num_heads = 8  # Number of self-attention heads\n",
    "d_k = 512  # Dimensionality of the linearly projected queries and keys\n",
    "batch_size = 64  # Batch size from the training process\n",
    "dropout_rate = 0.1 # The dropout propability for the attention weights\n",
    " \n",
    "x = np.random.random((batch_size, input_seq_length, d_k))\n",
    "\n",
    "self_attention_test = GlobalSelfAttention(num_heads, d_k, dropout_rate)\n",
    "feedforward_test = FeedForward(d_k, 2048)\n",
    "feedforward_test(self_attention_test(x)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a558a3-8941-4e2e-9c58-ffcbdb140cf5",
   "metadata": {},
   "source": [
    "## EncoderLayer Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35636464-12cb-4880-abe7-fbad856e63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_heads, d_k, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.self_attention_layer = GlobalSelfAttention(num_heads, d_k, dropout_rate)\n",
    "        self.ffn = FeedForward(d_k, dff)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.self_attention_layer(x)\n",
    "        x = self.ffn(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9dac1730-7397-4b32-af60-92c9b770eb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 5, 512])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "num_heads = 8  # Number of self-attention heads\n",
    "d_k = 512  # Dimensionality of the linearly projected queries and keys\n",
    "batch_size = 64  # Batch size from the training process\n",
    "dropout_rate = 0.1 # The dropout propability for the attention weights\n",
    " \n",
    "x = np.random.random((batch_size, input_seq_length, d_k))\n",
    "\n",
    "encoder_layer_test = EncoderLayer(num_heads, d_k, 2048, dropout_rate)\n",
    "encoder_layer_test(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1a063b-099f-489f-a450-cbd1457214ad",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4f53c151-e22f-4805-b0e4-38d91f2b8583",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, vocab_size, d_k, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.input_embedding_layer = InputEmbedding(vocab_size, d_k)\n",
    "        self.positional_embedding_layer = PositionalEmbedding(d_k)\n",
    "        self.dropout_layer = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.encoder_layers = tf.keras.Sequential([\n",
    "            EncoderLayer(num_heads, d_k, dff, dropout_rate)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.input_embedding_layer(x)\n",
    "        x = self.positional_embedding_layer(x)\n",
    "        x = self.dropout_layer(x)\n",
    "        x = self.encoder_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5393455a-109b-4878-8043-f6ef18c69a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1024, 512)\n",
      "(64, 1024, 512)\n"
     ]
    }
   ],
   "source": [
    "input_seq_length = 5  # Maximum length of the input sequence\n",
    "num_layers = 3 # Number of encoder layers\n",
    "num_heads = 8  # Number of self-attention heads\n",
    "d_k = 512  # Dimensionality of the linearly projected queries and keys\n",
    "dff = 2048\n",
    "dropout_rate = 0.1 # The dropout propability for the attention weights\n",
    "vocab_size = moves_vectorizer.vocabulary_size()\n",
    "\n",
    "encoder_test = Encoder(num_layers, vocab_size, d_k, num_heads, dff, dropout_rate)\n",
    "for moves, elo, result in ds.take(2):\n",
    "    print(encoder_test(moves, training=True).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cbd7d-f9c6-488a-8217-6836a04b8d18",
   "metadata": {},
   "source": [
    "## EloRegression Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e32d582-3b11-491d-af78-f45b098f9b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EloRegression(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        ])\n",
    "        # We will output two elo scores\n",
    "        self.output_layer = tf.keras.layers.Dense(2, activation=\"relu\")\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8befccc-8069-48ce-8ccc-6d4d9914cfcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 2])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = 512  # Dimensionality of the linearly projected queries and keys\n",
    "batch_size = 64  # Batch size from the training process\n",
    "\n",
    "x = np.random.random((batch_size, d_k))\n",
    "elo_regression_test = EloRegression()\n",
    "elo_regression_test(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f497d9d-fec0-42c0-a841-a26d52654e97",
   "metadata": {},
   "source": [
    "## ResultClassification Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bed20282-9a02-483f-934b-d44ae7e19339",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultClassification(tf.keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layers = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "            tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        ])\n",
    "        # There are three possible results\n",
    "        self.output_layer = tf.keras.layers.Dense(3, activation=\"softmax\")\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.hidden_layers(x)\n",
    "        x = self.output_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74dd9d89-e836-4279-aff7-7b28513ba503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 3])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = 512  # Dimensionality of the linearly projected queries and keys\n",
    "batch_size = 64  # Batch size from the training process\n",
    "\n",
    "x = np.random.random((batch_size, d_k))\n",
    "result_classification_test = ResultClassification()\n",
    "result_classification_test(x).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec0258-792c-4f42-b590-9f5b6102f3e7",
   "metadata": {},
   "source": [
    "## Chessformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcf252fe-2aaf-4c65-9d14-47ab3cd89eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Chessformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, vocab_size, d_k, num_heads, dff, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(num_layers, vocab_size, d_k, num_heads, dff, dropout_rate)\n",
    "        self.elo_regression_head = EloRegression()\n",
    "        self.result_classification_head = ResultClassification()\n",
    "\n",
    "    def call(self, moves):\n",
    "        moves = self.encoder(moves)\n",
    "        # moves.shape == (batch_num, sentence_length, d_k)\n",
    "        game_embedding = tf.reduce_mean(moves, axis=1) # Average the embeddings for all tokens\n",
    "        elos = self.elo_regression_head(game_embedding)\n",
    "        result = self.result_classification_head(game_embedding)\n",
    "        return elos, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7e1af32e-93af-4a01-9eb2-1acb23ca2b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elos: (64, 2)\n",
      "Result: (64, 3)\n"
     ]
    }
   ],
   "source": [
    "num_layers = 3 # Number of encoder layers\n",
    "num_heads = 8  # Number of self-attention heads\n",
    "d_k = 512  # Dimensionality of the linearly projected queries and keys\n",
    "dff = 2048\n",
    "dropout_rate = 0.1 # The dropout propability for the attention weights\n",
    "vocab_size = moves_vectorizer.vocabulary_size()\n",
    "\n",
    "chessformer_test = Chessformer(num_layers, vocab_size, d_k, num_heads, dff, dropout_rate)\n",
    "for moves, elos, result in ds.take(1):\n",
    "    elos, result = chessformer_test(moves)\n",
    "    print(f\"Elos: {elos.shape}\")\n",
    "    print(f\"Result: {result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a26a633-fa51-40de-8933-73d3efcc1a7b",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "52276c07-52cc-40ce-9cf6-6f977f6c176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 6\n",
    "vocab_size = moves_vectorizer.vocabulary_size()\n",
    "d_k = 512\n",
    "num_heads = 8\n",
    "dff = 2048\n",
    "dropout_rate = 0.1\n",
    "\n",
    "model = Chessformer(num_layers, vocab_size, d_k, num_heads, dff, dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "137f4232-8eca-4ff0-9f79-1744b33d0e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_k, warmup_steps=4000):\n",
    "        super().__init__()\n",
    "        self.d_k = tf.cast(d_k, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "        \n",
    "    def __call__(self, step):\n",
    "        step = tf.cast(step, dtype=tf.float32)\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_k) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a532d652-accb-400c-bc27-dccd5aa5f159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "learning_rate = CustomSchedule(d_k)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5267be2d-7d2c-4c64-886b-5f0ab84e1d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUM_OVER_BATCH_SIZE = tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE\n",
    "\n",
    "elo_loss_fn = tf.keras.losses.MeanSquaredError(reduction=SUM_OVER_BATCH_SIZE)\n",
    "result_loss_fn = tf.keras.losses.CategoricalCrossentropy(reduction=SUM_OVER_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a809cf9-cd2d-49a2-823e-f98c124f3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_elo_error_metric = tf.keras.metrics.MeanSquaredError()\n",
    "val_elo_error_metric = tf.keras.metrics.MeanSquaredError()\n",
    "\n",
    "train_result_acc_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_result_acc_metric = tf.keras.metrics.CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5388e3e8-8a3c-435a-89e6-08b149c6dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(moves, true_elos, true_results):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predicted_elos, predicted_results = model(moves, training=True)\n",
    "        elo_loss = elo_loss_fn(true_elos, predicted_elos)\n",
    "        result_loss = result_loss_fn(true_results, predicted_results)\n",
    "        loss_value = elo_loss + result_loss\n",
    "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
    "    train_elo_error_metric.update_state(true_elos, predicted_elos)\n",
    "    train_result_acc_metric.update_state(true_results, predicted_results)\n",
    "    return loss_value\n",
    "\n",
    "@tf.function\n",
    "def val_step(moves, true_elos, true_results):\n",
    "    predicted_elos, predicted_result = model(moves, training=False)\n",
    "    val_elo_error_metric.update_state(true_elos, predicted_elos)\n",
    "    val_result_acc_metric.update_state(true_results, predicted_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f553c2c7-608e-411f-b43a-910ad804d6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ds.take(1000)\n",
    "val_dataset = ds.skip(1000).take(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f60be-a6f9-4fe4-ac50-9df7d06cf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "for epoch in range(epochs):\n",
    "    print(f\"\\nStart of epoch {epoch}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over the batches of the dataset.\n",
    "    for step, (moves, true_elos, true_results) in enumerate(train_dataset):\n",
    "        loss_value = train_step(moves, true_elos, true_results)\n",
    "\n",
    "        # Log every 200 batches.\n",
    "        if step % 200 == 0:\n",
    "            print(\n",
    "                f\"Training loss (for one batch) at step {step}: {float(loss_value):.4f}\")\n",
    "            print(f\"Seen so far: {(step + 1) * batch_size} samples\")\n",
    "\n",
    "    # Display metrics at the end of each epoch.\n",
    "    train_elo_error = train_elo_error_metric.result()\n",
    "    train_result_acc = train_result_acc_metric.result()\n",
    "    print(f\"Elo training error over epoch: {train_elo_error:.4f}\")\n",
    "    print(f\"Result training accuracy over epoch: {train_result_acc:.4f}\")\n",
    "\n",
    "    # Reset training metrics at the end of each epoch\n",
    "    train_elo_error_metric.reset_states()\n",
    "    train_result_acc_metric.reset_states()\n",
    "\n",
    "    # Run a validation loop at the end of each epoch.\n",
    "    for moves, true_elos, true_results in val_dataset:\n",
    "        test_step(moves, true_elos, true_results)\n",
    "\n",
    "    val_elo_error = val_elo_error_metric.result()\n",
    "    val_result_acc = val_result_acc_metric.result()\n",
    "    print(f\"Elo validation error over epoch: {val_elo_error:.4f}\")\n",
    "    print(f\"Result validation accuracy over epoch: {val_result_acc:.4f}\")\n",
    "    val_elo_error_metric.reset_states()\n",
    "    val_result_acc_metric.reset_states()\n",
    "    print(f\"Time taken: {time.time() - start_time:.2fs}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
