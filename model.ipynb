{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11a6f4f0-cf63-4588-a888-e57cc37f5355",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b04ffbdf-d133-4191-ad92-4d9e644a8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399025ed-93fa-48b2-b8e1-70822332edca",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2315f77-2c14-4600-9535-7f7f9bebd521",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_DIR = \"data/training_data\"\n",
    "\n",
    "data_files = [f\"{TRAINING_DATA_DIR}/{file}\" for file in os.listdir(TRAINING_DATA_DIR)]\n",
    "dataset = tf.data.TFRecordDataset(filenames=data_files,\n",
    "                                  compression_type=\"GZIP\",\n",
    "                                  num_parallel_reads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9d82c60-c58d-4231-8b80-086b166f1d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-1 -> [0. 1. 0. 0.]\n",
      "1-0 -> [0. 0. 1. 0.]\n",
      "1/2-1/2 -> [0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "possible_results = [\"0-1\", \"1-0\", \"1/2-1/2\"]\n",
    "result_to_onehot = tf.keras.layers.StringLookup(\n",
    "    vocabulary=possible_results, output_mode=\"one_hot\")\n",
    "\n",
    "for result in possible_results:\n",
    "    print(f\"{result} -> {result_to_onehot(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b6304c-0e4c-460c-8323-6cf4b120e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example conversion\n",
      "Original: p e2 e4 - p a7 a5 - b f1 c4 - p c7 c5 - q d1 f3 - p e7 e5 - q f3 f7 -\n",
      "Vectorized: [ 2 20 36 72  2 56 40 72  4 13 34 72  2 58 42 72  6 11 29 72  2 60 44 72\n",
      "  6 29 61 72  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "\n",
      "p -> 2\n",
      "n -> 3\n",
      "b -> 4\n",
      "r -> 5\n",
      "q -> 6\n",
      "k -> 7\n",
      "a1 -> 8\n",
      "b1 -> 9\n",
      "c1 -> 10\n",
      "d1 -> 11\n",
      "e1 -> 12\n",
      "f1 -> 13\n",
      "g1 -> 14\n",
      "h1 -> 15\n",
      "a2 -> 16\n",
      "b2 -> 17\n",
      "c2 -> 18\n",
      "d2 -> 19\n",
      "e2 -> 20\n",
      "f2 -> 21\n",
      "g2 -> 22\n",
      "h2 -> 23\n",
      "a3 -> 24\n",
      "b3 -> 25\n",
      "c3 -> 26\n",
      "d3 -> 27\n",
      "e3 -> 28\n",
      "f3 -> 29\n",
      "g3 -> 30\n",
      "h3 -> 31\n",
      "a4 -> 32\n",
      "b4 -> 33\n",
      "c4 -> 34\n",
      "d4 -> 35\n",
      "e4 -> 36\n",
      "f4 -> 37\n",
      "g4 -> 38\n",
      "h4 -> 39\n",
      "a5 -> 40\n",
      "b5 -> 41\n",
      "c5 -> 42\n",
      "d5 -> 43\n",
      "e5 -> 44\n",
      "f5 -> 45\n",
      "g5 -> 46\n",
      "h5 -> 47\n",
      "a6 -> 48\n",
      "b6 -> 49\n",
      "c6 -> 50\n",
      "d6 -> 51\n",
      "e6 -> 52\n",
      "f6 -> 53\n",
      "g6 -> 54\n",
      "h6 -> 55\n",
      "a7 -> 56\n",
      "b7 -> 57\n",
      "c7 -> 58\n",
      "d7 -> 59\n",
      "e7 -> 60\n",
      "f7 -> 61\n",
      "g7 -> 62\n",
      "h7 -> 63\n",
      "a8 -> 64\n",
      "b8 -> 65\n",
      "c8 -> 66\n",
      "d8 -> 67\n",
      "e8 -> 68\n",
      "f8 -> 69\n",
      "g8 -> 70\n",
      "h8 -> 71\n",
      "- -> 72\n",
      "=n -> 73\n",
      "=b -> 74\n",
      "=r -> 75\n",
      "=q -> 76\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 1024\n",
    "\n",
    "pieces = [\"p\", \"n\", \"b\", \"r\", \"q\", \"k\"]\n",
    "rank_names = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\"]\n",
    "file_names = [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"]\n",
    "squares = [f + r for r in rank_names for f in file_names]\n",
    "promotions = [\"-\", \"=n\", \"=b\", \"=r\", \"=q\"]\n",
    "possible_tokens = pieces + squares + promotions\n",
    "\n",
    "moves_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    output_mode=\"int\",\n",
    "    vocabulary=possible_tokens,\n",
    "    standardize=None,\n",
    "    split=\"whitespace\",\n",
    "    output_sequence_length=MAX_SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "print(\"Example conversion\")\n",
    "sample_game = \"p e2 e4 - p a7 a5 - b f1 c4 - p c7 c5 - q d1 f3 - p e7 e5 - q f3 f7 -\"\n",
    "print(\"Original:\", sample_game)\n",
    "print(\"Vectorized:\", moves_vectorizer(sample_game).numpy()[:40])\n",
    "print()\n",
    "\n",
    "for token in possible_tokens:\n",
    "    print(f\"{token} -> {moves_vectorizer(token)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4d06f5-b3c7-4a16-8946-db0b2e82a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "feature_description = {\n",
    "    \"moves\": tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "    \"white_elo\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"black_elo\": tf.io.FixedLenFeature([], tf.int64, default_value=0),\n",
    "    \"result\": tf.io.FixedLenFeature([], tf.string, default_value=''),\n",
    "}\n",
    "\n",
    "def prepare_example(example_proto):\n",
    "    example = tf.io.parse_example(example_proto, feature_description)\n",
    "    result_embedding = result_to_onehot(example[\"result\"])\n",
    "    tokenized_moves = moves_vectorizer(example[\"moves\"])\n",
    "    return tokenized_moves, example[\"white_elo\"], example[\"black_elo\"], result_embedding\n",
    "\n",
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(prepare_example, tf.data.AUTOTUNE)\n",
    "      .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "ds = make_batches(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714d1d89-4933-4ad9-b9c8-7649440adf94",
   "metadata": {},
   "source": [
    "## InputEmbedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "597bdfeb-0135-4c41-b2e6-a7a4bfb4af5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embedding_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding_layer(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.embedding_dim, tf.float32))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c18d01e7-bbbd-4408-bcbd-2ea031ba3ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 0.08719932 -0.01575967  0.0407076   0.10681532 -0.02268509]\n",
      "  [ 0.07930453 -0.06022277  0.05317946 -0.05750503  0.07510678]\n",
      "  [-0.07729118  0.10778025  0.04365802  0.10368367  0.05111607]\n",
      "  ...\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]]\n",
      "\n",
      " [[ 0.08719932 -0.01575967  0.0407076   0.10681532 -0.02268509]\n",
      "  [ 0.07930453 -0.06022277  0.05317946 -0.05750503  0.07510678]\n",
      "  [-0.07729118  0.10778025  0.04365802  0.10368367  0.05111607]\n",
      "  ...\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]]\n",
      "\n",
      " [[ 0.08719932 -0.01575967  0.0407076   0.10681532 -0.02268509]\n",
      "  [ 0.05297581 -0.05138646 -0.0228233  -0.06464192  0.00070788]\n",
      "  [ 0.00218857  0.0010532   0.06446736  0.06184484 -0.01458992]\n",
      "  ...\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.08719932 -0.01575967  0.0407076   0.10681532 -0.02268509]\n",
      "  [ 0.05297581 -0.05138646 -0.0228233  -0.06464192  0.00070788]\n",
      "  [ 0.00218857  0.0010532   0.06446736  0.06184484 -0.01458992]\n",
      "  ...\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]]\n",
      "\n",
      " [[ 0.08719932 -0.01575967  0.0407076   0.10681532 -0.02268509]\n",
      "  [ 0.05297581 -0.05138646 -0.0228233  -0.06464192  0.00070788]\n",
      "  [ 0.00218857  0.0010532   0.06446736  0.06184484 -0.01458992]\n",
      "  ...\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]]\n",
      "\n",
      " [[ 0.08719932 -0.01575967  0.0407076   0.10681532 -0.02268509]\n",
      "  [ 0.07930453 -0.06022277  0.05317946 -0.05750503  0.07510678]\n",
      "  [-0.07729118  0.10778025  0.04365802  0.10368367  0.05111607]\n",
      "  ...\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]\n",
      "  [ 0.03788096 -0.05493489  0.04061383 -0.10936422 -0.00659587]]], shape=(64, 1024, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = moves_vectorizer.vocabulary_size()\n",
    "test_input_embedding = InputEmbedding(vocab_size=vocab_size, embedding_dim=5)\n",
    "for moves, white_elo, black_elo, result in ds.take(1):\n",
    "    print(test_input_embedding(moves))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c2525a-ddd9-442f-a895-bb3564eab8c8",
   "metadata": {},
   "source": [
    "## PositionalEmbedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "acbe47b6-db96-4185-aac2-68ed8c150897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(length, depth):\n",
    "    half_depth = depth / 2\n",
    "    \n",
    "    positions = np.arange(length)[:, np.newaxis]\n",
    "    depths = np.arange(half_depth)[np.newaxis, :] / half_depth\n",
    "    \n",
    "    angle_rates = 1 / (10000**depths)\n",
    "    angle_rads = positions * angle_rates\n",
    "\n",
    "    sin = np.sin(angle_rads)\n",
    "    cos = np.cos(angle_rads)\n",
    "\n",
    "    positional_encoding = np.dstack((sin, cos)).reshape(sin.shape[0],-1)[:,:depth]\n",
    "    \n",
    "    return positional_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6e1ae8f3-9960-408a-a30a-6adab697cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(tf.keras.layers.Layer):\n",
    "    def __init__(self, sequence_length, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.positional_embedding = positional_encoding(\n",
    "            length=sequence_length, depth=embedding_dim)\n",
    "        print(self.positional_embedding.shape)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x += self.positional_embedding\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f1bd7818-3856-4d50-a74c-c01f1fed1691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 5), dtype=float32, numpy=\n",
       "array([[ 0.0000000e+00,  1.0000000e+00,  0.0000000e+00,  1.0000000e+00,\n",
       "         0.0000000e+00],\n",
       "       [ 8.4147096e-01,  5.4030228e-01,  2.5116222e-02,  9.9968451e-01,\n",
       "         6.3095731e-04],\n",
       "       [ 9.0929741e-01, -4.1614684e-01,  5.0216600e-02,  9.9873835e-01,\n",
       "         1.2619144e-03],\n",
       "       [ 1.4112000e-01, -9.8999250e-01,  7.5285293e-02,  9.9716204e-01,\n",
       "         1.8928709e-03],\n",
       "       [-7.5680250e-01, -6.5364361e-01,  1.0030649e-01,  9.9495661e-01,\n",
       "         2.5238267e-03],\n",
       "       [-9.5892429e-01,  2.8366220e-01,  1.2526439e-01,  9.9212337e-01,\n",
       "         3.1547814e-03],\n",
       "       [-2.7941549e-01,  9.6017027e-01,  1.5014327e-01,  9.8866427e-01,\n",
       "         3.7857350e-03],\n",
       "       [ 6.5698659e-01,  7.5390226e-01,  1.7492741e-01,  9.8458135e-01,\n",
       "         4.4166869e-03],\n",
       "       [ 9.8935825e-01, -1.4550003e-01,  1.9960120e-01,  9.7987723e-01,\n",
       "         5.0476375e-03],\n",
       "       [ 4.1211849e-01, -9.1113025e-01,  2.2414905e-01,  9.7455490e-01,\n",
       "         5.6785857e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 10\n",
    "dim = 5\n",
    "positional_embedding_test = PositionalEmbedding(length, dim)\n",
    "x = np.zeros((length, dim))\n",
    "positional_embedding_test(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
